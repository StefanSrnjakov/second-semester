NNKR - Priprava na kolokvij

- 10 vprašanj, pišemo 45 minut

SNOV
- Kritika Turingovega stroja, v čem se arhitektura Turingovega stroja razlikuje od možganov
- Pri možganih je osnovna enota nevron, ki skrbi za celotno delovanje
- Pomembna je primerjava med Turingovim strojem in možgani
- Na 1. kolokviju ne bo nič o kvantnem svetu

- Možgani so taka fajn snov - Holobar 2024
- Pomembne so različne informacije o možganih, anatomije pa ne bo
- Funkcije sivine in beline možganov
- Kaj so dendriti, kaj je akson, kaj so mielinske ovojnice -> snov Nevroni (Mozgani.pptx, str 15). Pomembno znat še dodatne informacije, ki niso zapisane v predstavitvi
- Ni potrebno specifično znanje o plasteh
- Nevrotransmiterji niso preveč pomembni, nismo podrobno obravnavali
- Propagacija signala, akcijski potencial, črpanje signala. Ni potrebno poznat razlik med ioni, potreben pa opis delovanja
- Večji kot je dražljaj, več senzorjev se aktivira. Dve modulacije informacije

- Vmesniki človek/možgani stroja
- Valovanje Alfa, Beta, Gamma (Delta, Theta) valovanje. Kdaj nastopi katero od valovanj? Kako so pomembna? Lestvica.
- Potenciali
- Osamelci
- Prečna koleracija

- Osnovni princip delovanja kodirnik in dekodirnik

- Kolokvij 1. bo temeljil na PCA

PRAŠANJA

primerjava neuromorfnih s turingovo arhitekturo (bottleneck) 
koliko nevronov v kortikolarnih stolpickih in koliko kortikolarnih v mozganih 
asociativni spomin in kortikolarni - kako so kortikolarni povezani
Katero valovanje možganov med pisanjem kolokvija
Kdaj PCA ni primerna in podaj primer 
Predpriprava podatkov za PCA


slika! Kako predprocesirat ta primer 
kako ohraniti dolocen odstotek energije pri PCA
Najboljsi in najslabsi primer za PCA (z x1 in x2 osmi. Torej razpršene pike ali pike grejo v neko smer - not to be confused with graf s energijami)
Kaj je pri gradientni optimizaciji problem lokalnih minimumov?
kaj na pomaga da vemo ce so nadgaussove in podgaussove razporeditve?

--------- KOLOKVIJ 2. ---------


1. kaj je hebbova teorija in kaj to pomeni v smislu nevromorfnih arhitektur?
   - (cells that fire together, wire togehter)
2. zapisi stevila 1, 2, 4 in 8 v kvantni obliki. ali lahko to napisemo s tenzorskim produktom? -> vecer
3. haddamardova vrata. mores z njimi izracunat kvantni bit 1/sqrt(2)|0> in 1/2*(1 + i)|1>
4. Ali sta ta dva kvantna bita prepeletena ali sta ločljiva? 1/sqrt(2)|10> in 1/sqrt(2)|11>
5. Kaj naredimo če pri shorovem algoritmu celega števila ne moremo faktorizirati na posamezne faktorje?
6. Na kaj moremo bit pozorni pri Grover-jevem algoritmu?
7. napiši presdovkod algoritma BB84

1. BB84 (z svojim besadami)
   - ka je varno in kaj ni varno
2. DiVincenzova merila
3. Kaj je Dekonherenca
4. Kaj je najveca bolecina prenosa programskih nevronskih mrez. (skalabilnost, multitasking)
5. Enonamensko vezje mi zelimo splosnonamensko vezje. Kako to naredimo?
6. Nadzorovano in ne nadzorovano ucenje 
7. NM (learning rule) (kaj smo se ucili)
8. Skupni vektorski prostor (perceptron)
9. SOM (posodabljana utezi, kaj se spremeni)
10. Hebbova teorija (kaj pravi kaj pomeni dejansko)
11. Pravilo ucenja, delitev stroska (vzratno ucenje) - problem izginijajocih gradientov, strosek izginijajocih gradientov.
12. Zakaj je treba nevronske mreze veckrat uciti, kako nastavimo utezi, random nastavimo utezi - zakaj kaj je treba pazit?
13. Zakaj se uproablja aktivacijske funkcije? (za obvladanje osamelcev-outliers, sigmoidna aktivacijska func)
14. Schrödingerjeva enacba, macka (lahko splosno)
15. Kaj je nedeterministicnost, lokalnost... itd.
16. Kaj omogoca superpozicija, prepletanje, matricni produkt...
17. Kvantna mehanika - pretvorba, notacija, izracun, matricna prezentacija.
18. Tenzorski produkt (razumljivost, primeri).
19. Kvantna vrata (lahko).
20. ( ---- ? -----) Blokova sfera (lahko, moras znati brat). ( ---- ? -----)
21. Kontrolirana ne-vrata (c).
22. Pripravi, razvij in izmeri (razumevanje, S svojimi besedami).
23. ( ---- ? -----) Matrike razumevanje (Douchev algoritem), racunanje. ( ---- ? -----)
24. Shorov algoritem (funkcijo razlozi).
25. Zaporedje vrat (pravi vrstni red), posamezni koraki (zakaj rabim tega, zakaj tega... itd.). V kakem zaporedju kir korak in zakaj. Lahko slika in poves v katerem koraku smo.
26. Primer superpozicije (konstruktivna ali destruktivna, prepoznaj iz slike).
27. Kaj vpliva na amplitude verjetnosti.
28. Katere lastnosti pripisemo Shorovem algoritmu katere ne, kaj je stohasticnost
29. Casovne zahtevnosti.
30. Kaj se zgodi ce kiksnemo st interacij pri Groverju (more biti tocno st. interacij), ne uci se korakov.